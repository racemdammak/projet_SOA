# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12PK-NBriJ7PeWj0m52tFaSREVgAL3CNP
"""

import pandas as pd

# File paths
arsenal_filepath = "results_arsenal.csv"
madrid_filepath = "results_real_madrid.csv"

# Load datasets
arsenal_df = pd.read_csv(arsenal_filepath)
madrid_df = pd.read_csv(madrid_filepath)

# Convert 'GF' column in Arsenal dataset to numeric
arsenal_df['GF'] = pd.to_numeric(arsenal_df['GF'], errors='coerce')
madrid_df['GF'] = pd.to_numeric(madrid_df['GF'], errors='coerce')

# Fill missing values in 'xG' and 'xGA' using the rolling mean of last 5 matches
for df in [arsenal_df, madrid_df]:
    df['xG'] = df['xG'].fillna(df['xG'].rolling(5, min_periods=1).mean())
    df['xGA'] = df['xGA'].fillna(df['xGA'].rolling(5, min_periods=1).mean())

arsenal_df.columns

columns = ['Date', 'Comp', 'Round', 'Opponent', 'Formation', 'Opp Formation']
arsenal_df = arsenal_df.drop(columns=columns)

# Function to enhance feature engineering
def create_features_advanced(df, team_name):
    features = []

    for i in range(5, len(df)):
        window = df.iloc[i-5:i]  # Last 5 matches

        feat = {
            'team': team_name,
            'avg_xG': window['xG'].mean(),
            'avg_xGA': window['xGA'].mean(),
            'win_pct': (window['Result'] == 'W').mean(),
            'draw_pct': (window['Result'] == 'D').mean(),
            'loss_pct': (window['Result'] == 'L').mean(),
            'possession': window['Poss'].mean(),
            'goals_scored': window['GF'].mean(),
            'goals_conceded': window['GA'].mean(),
            'goal_difference': (window['GF'] - window['GA']).mean(),
            'streak': sum(1 if res == 'W' else -1 if res == 'L' else 0 for res in window['Result']),
            'home_advantage': (window['Venue'] == 'Home').mean(),
            'last_result': 1 if df.iloc[i-1]['Result'] == 'W' else -1 if df.iloc[i-1]['Result'] == 'L' else 0,
        }
        features.append(feat)

    return pd.DataFrame(features)

# Apply feature engineering to both teams
arsenal_features = create_features_advanced(arsenal_df, 'Arsenal')
madrid_features = create_features_advanced(madrid_df, 'Real Madrid')

# Display updated features
arsenal_features.head(), madrid_features.head()

# Ensure both datasets have the same length
common_length = min(len(arsenal_features), len(madrid_features))

# Create matchup dataset
matchups = []
results = []

for i in range(common_length):
    a_row = arsenal_features.iloc[i]
    m_row = madrid_features.iloc[i]

    matchup = {
        'arsenal_xG': a_row['avg_xG'],
        'arsenal_xGA': a_row['avg_xGA'],
        'arsenal_win_pct': a_row['win_pct'],
        'arsenal_possession': a_row['possession'],
        'madrid_xG': m_row['avg_xG'],
        'madrid_xGA': m_row['avg_xGA'],
        'madrid_win_pct': m_row['win_pct'],
        'madrid_possession': m_row['possession'],
        'xG_diff_diff': a_row['xG_diff'] - m_row['xG_diff'],
        'home_advantage': a_row['home_advantage']  # Arsenal at home
    }

    matchups.append(matchup)

    # Determine result from Arsenal's perspective
    if a_row['last_result'] == 1:  # Arsenal won last match
        results.append(1)  # Arsenal wins
    elif a_row['last_result'] == -1:  # Arsenal lost last match
        results.append(-1)  # Arsenal loses
    else:
        results.append(0)  # Draw

# Convert to DataFrame
X = pd.DataFrame(matchups)
y = results

from sklearn.model_selection import train_test_split
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score

# Combine both teams' data
full_dataset = pd.concat([arsenal_features, madrid_features], ignore_index=True)
full_results = pd.concat([arsenal_df['Result'], madrid_df['Result']], ignore_index=True)
# Define features and target variable
X = full_dataset  # Features
y = full_results  # Target variable

# Split data into training and testing sets (80-20 split)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train XGBoost model
xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')
xgb_model.fit(X_train, y_train)

# Predict and evaluate
y_pred = xgb_model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)

accuracy